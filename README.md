# Description
main.py - файл с сервисом

model.pkl - сохраненные веса модели

scaler.pkl - сохраненный скалер

train_median.pkl - сохраненные медианы из трейна

## Какие модели пробовали
Попробовали достаточно много разных линейных моделей и различные подходы в обработке признаков

Заметного улучшения метрик регуляризация и GridSearch не дали. Незначительного улучшения удалось достичь только после кодирования категориальных переменных

Для себя я пробовал обучить RandomForest и намного лучшие результаты (в notebook не сохранил), так что можно сделать вывод, что линейные модели - не лучший выбор для такой задачи

На удивление, лучшее значение бизнес-метрики показала модель LogisticRegression на нормализованных данных без категориальных фич. Именно ее я выбрал для реализации сервиса

## Сервис
Удалось реализовать сервис на FastApi который распадается на два случая:
- predict_item предсказание для одного объекта
- predict_csv предсказание для файла csv
Кажется удалось сделать так, чтобы потенциальные пропуски в обох случаях корректно обрабатывались и заполнялись средними из train

В качестве примера работы predict_item я взял конкретный пример из test, а для predict_csv я взял сырую df_test целиков

predict_item. Возвращает json признаки + предсказание
![image](https://github.com/user-attachments/assets/3a3287d6-da9d-4ede-8e77-3f41347a2e94)
predict_csv. Возвращает csv признаки + предсказание
![image](https://github.com/user-attachments/assets/39cad9c7-aa70-4134-b4bb-c6a3144390f0)


